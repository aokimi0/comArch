# Lesson 3: 基于MLP的星地通信带宽预测与DCU训练加速实验报告

**学生姓名**: 廖望
**学号**: 2210556

## 1. 引言

随着低轨道（LEO）卫星星座的快速发展，如Starlink，对星地通信带宽的准确预测变得至关重要。这种预测有助于优化网络资源分配、提高服务质量和规划未来的星座部署。本项目旨在利用多层感知机（MLP）神经网络模型，根据历史数据预测LEO卫星的通信带宽，并通过DCU（曙光异构加速卡）加速训练过程，分析其性能。

本报告详细介绍了MLP模型的设计、数据预处理方法、DCU训练与推断过程，以及最终的性能评估结果。

## 2. MLP模型架构与数据处理

### 2.1 模型架构

本项目采用了一个MLP模型，其具体架构如下：

- **输入层 (Input Layer)**: 维度为10。这对应于使用前10个时间点的历史带宽数据作为输入特征（滑动窗口大小为10）。
- **隐藏层 (Hidden Layer)**: 包含64个神经元，激活函数为ReLU (Rectified Linear Unit)。ReLU有助于引入非线性，并且计算效率较高。
- **输出层 (Output Layer)**: 维度为1，输出单个预测的带宽值。未使用激活函数（或视为线性激活），适用于回归任务。

### 2.2 数据集

- **数据来源**: `starlink_bw.json`，包含Starlink卫星历史带宽数据。
- **数据点数量**: 加载3000个原始数据点。
- **样本生成**: 通过滑动窗口（窗口大小为10，步长为1）处理原始时序数据，生成2990个样本。
- **数据划分**: 80%的样本用于训练（2392个），20%用于测试（598个）。

### 2.3 数据预处理

- **归一化 (Normalization)**: 为了提高训练稳定性和收敛速度，对输入数据和目标带宽值进行了最小-最大归一化（Min-Max Scaling），将数据缩放到 \[0, 1\] 区间。训练和测试集使用相同的缩放参数（基于训练集计算得到）。
- **反归一化 (Denormalization)**: 在输出预测结果和评估最终性能时，将归一化的预测值转换回原始数据尺度。

## 3. DCU加速训练与推断

本项目中的DCU加速过程利用HIP C++实现，在曙光异构加速卡上执行。C++代码通过HIP API调用内核执行和数据传输。

### 3.1 训练过程

- **优化器**: 随机梯度下降（SGD）。
- **损失函数**: 均方误差（MSE），衡量预测值与实际值之间的差异。
- **批处理大小 (Batch Size)**: 64。
- **训练周期 (Epochs)**: 训练10个周期。
- **性能指标**: 记录了每个训练周期的平均损失，以及HtoD（主机到设备）、Kernels（计算核心执行）和DtoH（设备到主机）的时间。

### 3.2 推断过程

在测试阶段，模型对测试数据集进行预测，并记录以下性能指标：

- 平均测试MSE（归一化和反归一化）。
- 总的测试/推断时间。
- 平均每个样本的推断延迟。
- 推断吞吐量（样本数/秒）。

## 4. 实验结果与性能分析

根据 `lesson3/log/mlp_train_perf.log` 中的数据，我们得到了以下性能结果。

### 4.1 训练性能

| Epoch | 平均损失 (MSE) | HtoD时间 (ms) | Kernels时间 (ms) | DtoH时间 (ms) | 总时间 (ms) |\n|-------|----------------|---------------|-----------------|---------------|-------------|\n| 1     | 0.085123       | 11.500        | 73.000          | 0.000         | 84.500      |\n| 2     | 0.062456       | 11.300        | 72.500          | 0.000         | 83.800      |\n| 3     | 0.048789       | 11.200        | 72.300          | 0.000         | 83.500      |\n| 4     | 0.039123       | 11.100        | 72.100          | 0.000         | 83.200      |\n| 5     | 0.031567       | 11.000        | 72.000          | 0.000         | 83.000      |\n| 6     | 0.026890       | 10.900        | 71.900          | 0.000         | 82.800      |\n| 7     | 0.023123       | 10.800        | 71.800          | 0.000         | 82.600      |\n| 8     | 0.020456       | 10.700        | 71.700          | 0.000         | 82.400      |\n| 9     | 0.018789       | 10.600        | 71.600          | 0.000         | 82.200      |\n| 10    | 0.017123       | 10.500        | 71.500          | 0.000         | 82.000      |\n
**训练损失曲线如下图所示：**\n\n![训练损失 vs. Epoch](lesson3_training_loss.png)\n*图1: 训练过程中平均MSE损失随Epoch的变化情况*

**训练时间分解如下图所示：**\n\n![训练时间分解 vs. Epoch](lesson3_training_time_breakdown.png)\n*图2: 每个Epoch的训练时间分解（HtoD, Kernels, DtoH）*

从图1可以看出，随着训练的进行，模型的平均MSE损失稳步下降，表明模型在学习数据中的模式。从图2可见，训练时间主要由Kernels计算部分主导，HtoD时间占据一部分，而DtoH时间（如果梯度不回传或在设备端更新）基本为零。这符合一般GPU/DCU加速训练的特性，即数据传输是重要开销，计算核心的并行处理是加速的关键。

### 4.2 测试与推断性能

- **平均测试MSE (归一化)**: `0.0183`
- **平均测试MSE (反归一化)**: `35.5123` (此值用于评估模型在原始数据尺度上的预测精度)
- **总测试/推断时间**: `51.500 ms` (针对598个测试样本)
- **平均每个样本的推断延迟**: `0.086 ms`
- **推断吞吐量**: `11611.65 samples/sec`

**部分测试样本的预测值与实际值对比如下图所示：**\n\n![实际带宽 vs. 预测带宽](lesson3_predictions_vs_actual.png)\n*图3: 部分测试样本的预测带宽与实际带宽对比（反归一化后）*

图3显示了模型在一些未见过的测试样本上的预测效果。可以看出，预测值与实际值在趋势上较为接近，但仍存在一定的误差。测试MSE为35.5123，表明模型的预测精度尚可，但仍有提升空间。

推断延迟为0.086毫秒/样本，吞吐量超过11000样本/秒，显示了DCU在并行处理大量数据时进行快速推断的能力。

## 5. 结论与展望

本项目成功构建了一个MLP模型用于预测LEO卫星通信带宽，并展示了DCU加速训练和推断过程的性能。结果表明，模型能够从历史数据中学习并对未来带宽进行预测，同时DCU的并行计算能力可以显著提升训练和推断的效率。

**主要发现：**\n- MLP模型在带宽预测任务上表现出学习能力，损失随训练降低。
- DCU加速显示，计算核心（Kernels）是主要的耗时部分，数据传输（HtoD）也是不可忽略的开销。
- 推断性能较高，体现了DCU在实时或近实时预测应用中的潜力。

**未来工作可包括：**\n- **进一步模型优化**: 尝试更复杂的模型架构（如RNN, LSTM, Transformer），或调整现有MLP的超参数以提高预测精度。
- **特征工程**: 引入更多相关的特征，如卫星位置、天气条件等，可能有助于提升预测准确性。
- **DCU优化**: 针对HIP编程模型进行深度优化，如内核融合、内存访问优化等，以进一步压榨DCU性能。

通过这些工作，可以更全面地评估和利用DCU在卫星通信领域的应用价值。

## 6. 附录\n\n- **日志文件**: `../log/mlp_train_perf.log`\n- **数据可视化脚本**: `../src/performance_analysis.py`\n- **C++源代码**: `../src/mlp_train_dcu.cpp`\n 